# -*- coding: utf-8 -*-
"""Final-ML_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LJ9zM5qrZUyFq57RPlcDnOlA65gogceC
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('/content/NFLX.csv',parse_dates = True, index_col = 'Date')
data.head()

data.info()

plt.figure(figsize=(10,5))
plt.plot(data['Low'],label = 'low')
plt.plot(data['High'],label = 'high')
plt.xlabel('Year')
plt.ylabel('Prices')
plt.title('High v/s Low Prices Comparison')
plt.legend()
plt.show()

x = data.iloc[:,1:2]          # Feature / dependent
y = data['Close']             # Target Variable /  Independent
x.head()

from sklearn.preprocessing import StandardScaler      # used to normalize the dataset
sc = StandardScaler()
x_data = sc.fit_transform(x.values)
x_data = pd.DataFrame(columns = x.columns,data = x_data,index = x.index)
x_data.head()

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_data,y,train_size = 0.8)

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(x_train,y_train)

y_pred = lr.predict(x_test)

y_test_range = [i for i in range (1,len(y_test)+1,1)]
plt.plot(y_test_range,y_test,label = 'actual')
plt.plot(y_test_range,y_pred,label = 'predicted')
plt.xlabel('No. of days')
plt.ylabel('Stock Price At Close Time')
plt.legend()
plt.show()

c = [i for i in range (1,len(y_test)+1,1)]
plt.plot(c,y_test)
plt.plot(c,y_pred,"--")

plt.plot(c,y_pred - y_test)

from sklearn.metrics import mean_squared_error,r2_score
mse= mean_squared_error(y_test,y_pred)
r2_score = r2_score(y_test,y_pred)
print(mse,r2_score)

"""LSTM Model - Long Short Term Memory"""

from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense

training_data = data.iloc[:,3:4]
sc = MinMaxScaler(feature_range=(0, 1))
training_data = sc.fit_transform(training_data)
training_data.shape

x_train, y_train = [], []        # Initialized empty lists to store training data
for i in range(60, 1259):
    x_train.append(training_data[i - 60:i, 0])
    y_train.append(training_data[i, 0])
x_train, y_train = np.array(x_train), np.array(y_train) # Convert list to array(to prepare for model training)

x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))
x_train.shape

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dense(units=1))
model.compile(optimizer='adam', loss='mean_squared_error')

hist = model.fit(x_train,y_train,epochs=20,batch_size=32,verbose=2)

plt.plot(hist.history['loss'])
plt.title('Training model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train'],loc='upper right')
plt.show()

test_data = data['Close'].values.reshape(-1, 1)
test_data_scaled = sc.transform(test_data)

y_prediction = model.predict(x_test)

x_test = []
for i in range(60, len(test_data_scaled)):
    x_test.append(test_data_scaled[i - 60:i, 0])

x_test = np.array(x_test)

x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

predicted_stock_price = model.predict(x_test)

predicted_stock_price = sc.inverse_transform(y_prediction)

print(predicted_stock_price)